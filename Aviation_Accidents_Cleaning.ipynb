{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7485d62",
   "metadata": {},
   "source": [
    "# Aviation Accidents Analysis\n",
    "\n",
    "You are part of a consulting firm that is tasked to do an analysis of commercial and passenger jet airline safety. The client (an airline/airplane insurer) is interested in knowing what types of aircraft (makes/models) exhibit low rates of total destruction and low likelihood of fatal or serious passenger injuries in the event of an accident. They are also interested in any general variables/conditions that might be at play. Your analysis will be based off of aviation accident data accumulated from the years 1948-2023. \n",
    "\n",
    "Our client is only interested in airplane makes/models that are professional builds and could potentially still be active. Assume a max lifetime of 40 years for a make/model retirement and make sure to filter your data accordingly (i.e. from 1983 onwards). They would also like separate recommendations for small aircraft vs. larger passenger models. **In addition, make sure that claims that you make are statistically robust and that you have enough samples when making comparisons between groups.**\n",
    "\n",
    "\n",
    "In this summative assessment you will demonstrate your ability to:\n",
    "- **Use Pandas to load, inspect, and clean the dataset appropriately.**\n",
    "- **Transform relevant columns to create measures that address the problem at hand.**\n",
    "- conduct EDA: visualization and statistical measures to systematically understand the structure of the data\n",
    "- recommend a set of airplanes and makes conforming to the client's request and identify at least *two* factors contributing to airplane safety. You must provide supporting evidence (visuals, summary statistics, tables) for each claim you make."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e582c5",
   "metadata": {},
   "source": [
    "### Make relevant library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a72188a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1fc321",
   "metadata": {},
   "source": [
    "## Data Loading and Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57becc28",
   "metadata": {},
   "source": [
    "### Load in data from the relevant directory and inspect the dataframe.\n",
    "- inspect NaNs, datatypes, and summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85235fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event.Id                      0\n",
      "Investigation.Type            0\n",
      "Accident.Number               0\n",
      "Event.Date                    0\n",
      "Location                     52\n",
      "Country                     226\n",
      "Latitude                  54507\n",
      "Longitude                 54516\n",
      "Airport.Code              38757\n",
      "Airport.Name              36185\n",
      "Injury.Severity            1000\n",
      "Aircraft.damage            3194\n",
      "Aircraft.Category         56602\n",
      "Registration.Number        1382\n",
      "Make                         63\n",
      "Model                        92\n",
      "Amateur.Built               102\n",
      "Number.of.Engines          6084\n",
      "Engine.Type                7096\n",
      "FAR.Description           56866\n",
      "Schedule                  76307\n",
      "Purpose.of.flight          6192\n",
      "Air.carrier               72241\n",
      "Total.Fatal.Injuries      11401\n",
      "Total.Serious.Injuries    12510\n",
      "Total.Minor.Injuries      11933\n",
      "Total.Uninjured            5912\n",
      "Weather.Condition          4492\n",
      "Broad.phase.of.flight     27165\n",
      "Report.Status              6384\n",
      "Publication.Date          13771\n",
      "dtype: int64\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 88889 entries, 0 to 88888\n",
      "Data columns (total 31 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Event.Id                88889 non-null  str    \n",
      " 1   Investigation.Type      88889 non-null  str    \n",
      " 2   Accident.Number         88889 non-null  str    \n",
      " 3   Event.Date              88889 non-null  str    \n",
      " 4   Location                88837 non-null  str    \n",
      " 5   Country                 88663 non-null  str    \n",
      " 6   Latitude                34382 non-null  object \n",
      " 7   Longitude               34373 non-null  object \n",
      " 8   Airport.Code            50132 non-null  str    \n",
      " 9   Airport.Name            52704 non-null  str    \n",
      " 10  Injury.Severity         87889 non-null  str    \n",
      " 11  Aircraft.damage         85695 non-null  str    \n",
      " 12  Aircraft.Category       32287 non-null  str    \n",
      " 13  Registration.Number     87507 non-null  str    \n",
      " 14  Make                    88826 non-null  str    \n",
      " 15  Model                   88797 non-null  str    \n",
      " 16  Amateur.Built           88787 non-null  str    \n",
      " 17  Number.of.Engines       82805 non-null  float64\n",
      " 18  Engine.Type             81793 non-null  str    \n",
      " 19  FAR.Description         32023 non-null  str    \n",
      " 20  Schedule                12582 non-null  str    \n",
      " 21  Purpose.of.flight       82697 non-null  str    \n",
      " 22  Air.carrier             16648 non-null  str    \n",
      " 23  Total.Fatal.Injuries    77488 non-null  float64\n",
      " 24  Total.Serious.Injuries  76379 non-null  float64\n",
      " 25  Total.Minor.Injuries    76956 non-null  float64\n",
      " 26  Total.Uninjured         82977 non-null  float64\n",
      " 27  Weather.Condition       84397 non-null  str    \n",
      " 28  Broad.phase.of.flight   61724 non-null  str    \n",
      " 29  Report.Status           82505 non-null  str    \n",
      " 30  Publication.Date        75118 non-null  str    \n",
      "dtypes: float64(5), object(2), str(24)\n",
      "memory usage: 21.0+ MB\n",
      "None\n",
      "       Number.of.Engines  Total.Fatal.Injuries  Total.Serious.Injuries  \\\n",
      "count       82805.000000          77488.000000            76379.000000   \n",
      "mean            1.146585              0.647855                0.279881   \n",
      "std             0.446510              5.485960                1.544084   \n",
      "min             0.000000              0.000000                0.000000   \n",
      "25%             1.000000              0.000000                0.000000   \n",
      "50%             1.000000              0.000000                0.000000   \n",
      "75%             1.000000              0.000000                0.000000   \n",
      "max             8.000000            349.000000              161.000000   \n",
      "\n",
      "       Total.Minor.Injuries  Total.Uninjured  \n",
      "count          76956.000000     82977.000000  \n",
      "mean               0.357061         5.325440  \n",
      "std                2.235625        27.913634  \n",
      "min                0.000000         0.000000  \n",
      "25%                0.000000         0.000000  \n",
      "50%                0.000000         1.000000  \n",
      "75%                0.000000         2.000000  \n",
      "max              380.000000       699.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xs/_w4zn5t54vv8bvs6knszrf3m0000gp/T/ipykernel_84841/181663341.py:1: DtypeWarning: Columns (0: Latitude, 1: Longitude, 2: Broad.phase.of.flight) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_df = pd.read_csv('data/AviationData.csv', encoding=\"latin1\")\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv('data/AviationData.csv', encoding=\"latin1\")\n",
    "\n",
    "print(data_df.isna().sum())\n",
    "print(data_df.info())\n",
    "print(data_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060d34a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US_State        0\n",
      "Abbreviation    0\n",
      "dtype: int64\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 62 entries, 0 to 61\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype\n",
      "---  ------        --------------  -----\n",
      " 0   US_State      62 non-null     str  \n",
      " 1   Abbreviation  62 non-null     str  \n",
      "dtypes: str(2)\n",
      "memory usage: 1.1 KB\n",
      "None\n",
      "       US_State Abbreviation\n",
      "count        62           62\n",
      "unique       62           62\n",
      "top     Alabama           AL\n",
      "freq          1            1\n"
     ]
    }
   ],
   "source": [
    "state_codes_df = pd.read_csv('data/USState_Codes.csv')\n",
    "print(state_codes_df.isna().sum())\n",
    "print(state_codes_df.info())\n",
    "print(state_codes_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y9a23qrpc3p",
   "metadata": {},
   "source": [
    "### Inspection Observations\n",
    "\n",
    "**Shape:** 88,889 rows × 31 columns\n",
    "\n",
    "**Missingness highlights:**\n",
    "| Column | % Missing | Notes |\n",
    "|---|---|---|\n",
    "| `Schedule` | 86% | Too sparse to be useful |\n",
    "| `Air.carrier` | 81% | Too sparse to be useful |\n",
    "| `FAR.Description` | 64% | Regulatory classification — mostly missing |\n",
    "| `Aircraft.Category` | 64% | Vehicle type — mostly missing |\n",
    "| `Latitude` / `Longitude` | ~61% | Location data mostly absent |\n",
    "| `Airport.Code` / `Airport.Name` | 44% / 41% | Partial coverage |\n",
    "| `Total.Fatal/Serious/Minor.Injuries` | ~13% | Will impute with 0 (no injuries reported) |\n",
    "| `Total.Uninjured` | 7% | Will impute with 0 |\n",
    "\n",
    "**Data type issues:**\n",
    "- `Event.Date` is stored as `str` — must convert to `datetime` before filtering to 1983+\n",
    "- `Latitude` / `Longitude` flagged as mixed types (numeric strings + NaN) — will be dropped\n",
    "- Injury columns are `float64` due to NaN presence\n",
    "\n",
    "**Consistency issues:**\n",
    "- `Make` column has duplicate entries from inconsistent casing (e.g., `\"Cessna\"` vs `\"CESSNA\"`) — will standardize with `.str.title()`\n",
    "- `Weather.Condition` has both `\"UNK\"` and `\"Unk\"` as unknown markers — will consolidate\n",
    "\n",
    "**`USState_Codes`:** Clean — 62 rows, no missing values, 2 columns (`US_State`, `Abbreviation`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9b8cc7",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23efd78",
   "metadata": {},
   "source": [
    "### Filtering aircrafts and events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c399343",
   "metadata": {},
   "source": [
    "We want to filter the dataset to include aircraft that the client is interested in an analysis of:\n",
    "- inspect relevant columns\n",
    "- figure out any reasonable imputations\n",
    "- filter the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a2b7eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigation.Type value counts:\n",
      "Investigation.Type\n",
      "Accident    85015\n",
      "Incident     3874\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Amateur.Built value counts:\n",
      "Amateur.Built\n",
      "No     80312\n",
      "Yes     8475\n",
      "NaN      102\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Shape before filtering: (88889, 31)\n",
      "Shape after date filter (1983+): (85289, 31)\n",
      "Shape after Amateur.Built filter: (76960, 31)\n",
      "Shape after Investigation.Type filter (Accidents only): (73286, 31)\n"
     ]
    }
   ],
   "source": [
    "# Inspect relevant columns before filtering\n",
    "print(\"Investigation.Type value counts:\")\n",
    "print(data_df['Investigation.Type'].value_counts(), \"\\n\")\n",
    "\n",
    "print(\"Amateur.Built value counts:\")\n",
    "print(data_df['Amateur.Built'].value_counts(dropna=False), \"\\n\")\n",
    "\n",
    "# Convert Event.Date to datetime for date-based filtering\n",
    "data_df['Event.Date'] = pd.to_datetime(data_df['Event.Date'])\n",
    "\n",
    "print(f\"Shape before filtering: {data_df.shape}\")\n",
    "\n",
    "# Filter 1: 1983 onwards (40-year max aircraft lifetime per client requirement)\n",
    "data_df = data_df[data_df['Event.Date'] >= '1983-01-01']\n",
    "print(f\"Shape after date filter (1983+): {data_df.shape}\")\n",
    "\n",
    "# Filter 2: Professional builds only (exclude amateur-built aircraft)\n",
    "data_df = data_df[data_df['Amateur.Built'] == 'No']\n",
    "print(f\"Shape after Amateur.Built filter: {data_df.shape}\")\n",
    "\n",
    "# Filter 3: Accidents only (exclude incidents — incidents are minor and don't reflect safety outcomes)\n",
    "data_df = data_df[data_df['Investigation.Type'] == 'Accident']\n",
    "print(f\"Shape after Investigation.Type filter (Accidents only): {data_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gn7ngi9xsu5",
   "metadata": {},
   "source": [
    "**Filtering decisions:**\n",
    "- **Date (1983+):** Client specified a 40-year max aircraft lifetime, so records prior to 1983 are excluded as they reflect retired models.\n",
    "- **Amateur.Built == 'No':** Client is only interested in professional/commercial aircraft. The ~102 NaN rows are also excluded since their build status is unknown.\n",
    "- **Investigation.Type == 'Accident':** Incidents are minor events that don't result in meaningful damage or injury outcomes. Including them would dilute safety metrics. Only ~4% of records are incidents, so this has minimal impact on sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d26002",
   "metadata": {},
   "source": [
    "### Cleaning and constructing Key Measurables\n",
    "\n",
    "Injuries and robustness to destruction are a key interest point for the client. Clean and impute relevant columns and then create derived fields that best quantifies what the client wishes to track. **Use commenting or markdown to explain any cleaning assumptions as well as any derived columns you create.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070b08f8",
   "metadata": {},
   "source": [
    "**Construct metric for fatal/serious injuries**\n",
    "\n",
    "*Hint:* Estimate the total number of passengers on each flight. The likelihood of serious / fatal injury can be estimated as a fraction from this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14qg1rhvml",
   "metadata": {},
   "source": [
    "**Cleaning assumptions:**\n",
    "- NaN values in all four injury columns (`Total.Fatal.Injuries`, `Total.Serious.Injuries`, `Total.Minor.Injuries`, `Total.Uninjured`) are imputed with **0**. Missing counts most likely indicate no injuries were recorded, not that the data is truly absent.\n",
    "- `Total.Passengers` is estimated as the sum of all four columns — this is the best available proxy for occupants on board since actual passenger manifests are not in the dataset.\n",
    "- `Injury.Rate` = (`Total.Fatal.Injuries` + `Total.Serious.Injuries`) / `Total.Passengers`. Records where `Total.Passengers == 0` (no occupant data at all) are set to `NaN` to avoid division by zero and misleading rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef28a6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts in injury columns:\n",
      "Total.Fatal.Injuries       9547\n",
      "Total.Serious.Injuries    10469\n",
      "Total.Minor.Injuries       9965\n",
      "Total.Uninjured            4766\n",
      "dtype: int64 \n",
      "\n",
      "Total.Passengers summary:\n",
      "count    73286.000000\n",
      "mean         4.507123\n",
      "std         21.643163\n",
      "min          0.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          2.000000\n",
      "max        699.000000\n",
      "Name: Total.Passengers, dtype: float64 \n",
      "\n",
      "Injury.Rate summary:\n",
      "count    72852.000000\n",
      "mean         0.286128\n",
      "std          0.434153\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: Injury.Rate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "injury_cols = ['Total.Fatal.Injuries', 'Total.Serious.Injuries',\n",
    "               'Total.Minor.Injuries', 'Total.Uninjured']\n",
    "\n",
    "# Inspect missing values before imputation\n",
    "print(\"NaN counts in injury columns:\")\n",
    "print(data_df[injury_cols].isna().sum(), \"\\n\")\n",
    "\n",
    "# Impute NaN with 0: missing injury counts most likely mean no injuries were recorded\n",
    "data_df[injury_cols] = data_df[injury_cols].fillna(0)\n",
    "\n",
    "# Estimate total passengers on board as sum of all injury/uninjured counts\n",
    "data_df['Total.Passengers'] = data_df[injury_cols].sum(axis=1)\n",
    "\n",
    "# Injury.Rate: fraction of passengers with fatal or serious injuries\n",
    "# Set to NaN where Total.Passengers == 0 (no occupant data recorded) to avoid division by zero\n",
    "data_df['Injury.Rate'] = np.where(\n",
    "    data_df['Total.Passengers'] > 0,\n",
    "    (data_df['Total.Fatal.Injuries'] + data_df['Total.Serious.Injuries']) / data_df['Total.Passengers'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "print(\"Total.Passengers summary:\")\n",
    "print(data_df['Total.Passengers'].describe(), \"\\n\")\n",
    "\n",
    "print(\"Injury.Rate summary:\")\n",
    "print(data_df['Injury.Rate'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c89136b",
   "metadata": {},
   "source": [
    "**Aircraft.Damage**\n",
    "- identify and execute any cleaning tasks\n",
    "- construct a derived column tracking whether an aircraft was destroyed or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whc978sh78q",
   "metadata": {},
   "source": [
    "**Cleaning assumptions:**\n",
    "- NaN values in `Aircraft.damage` (~4% of records) are filled with `'Unknown'` — damage status was simply not recorded; treating them as a separate category preserves these records rather than dropping them.\n",
    "- No casing standardization needed — all values (`Substantial`, `Destroyed`, `Minor`, `Unknown`) are already title case.\n",
    "- `Is.Destroyed` is a binary derived column: `1` if `Aircraft.damage == 'Destroyed'`, `0` otherwise. This directly captures the client's key concern about total loss events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91b518b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aircraft.damage value counts (including NaN):\n",
      "Aircraft.damage\n",
      "Substantial    55651\n",
      "Destroyed      15462\n",
      "NaN             1415\n",
      "Minor            664\n",
      "Unknown           94\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "NaN count after imputation: 0 \n",
      "\n",
      "Is.Destroyed value counts:\n",
      "Is.Destroyed\n",
      "0    57824\n",
      "1    15462\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Destruction rate: 21.1%\n"
     ]
    }
   ],
   "source": [
    "# Inspect Aircraft.damage\n",
    "print(\"Aircraft.damage value counts (including NaN):\")\n",
    "print(data_df['Aircraft.damage'].value_counts(dropna=False), \"\\n\")\n",
    "\n",
    "# Fill NaN with 'Unknown' — damage status was not recorded for these events\n",
    "data_df['Aircraft.damage'] = data_df['Aircraft.damage'].fillna('Unknown')\n",
    "\n",
    "# Verify no remaining NaNs\n",
    "print(\"NaN count after imputation:\", data_df['Aircraft.damage'].isna().sum(), \"\\n\")\n",
    "\n",
    "# Create binary Is.Destroyed column: 1 if the aircraft was fully destroyed, 0 otherwise\n",
    "data_df['Is.Destroyed'] = (data_df['Aircraft.damage'] == 'Destroyed').astype(int)\n",
    "\n",
    "print(\"Is.Destroyed value counts:\")\n",
    "print(data_df['Is.Destroyed'].value_counts())\n",
    "print(f\"\\nDestruction rate: {data_df['Is.Destroyed'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8af9b",
   "metadata": {},
   "source": [
    "### Investigate the *Make* column\n",
    "- Identify cleaning tasks here\n",
    "- List cleaning tasks clearly in markdown\n",
    "- Execute the cleaning tasks\n",
    "- For your analysis, keep Makes with a reasonable number (you can put the threshold at 50 though lower could work as well)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rkrlttbd7ic",
   "metadata": {},
   "source": [
    "**Identified cleaning tasks:**\n",
    "1. **Whitespace** — strip leading/trailing whitespace from all `Make` values\n",
    "2. **Inconsistent casing** — values like `\"CESSNA\"` and `\"Cessna\"` refer to the same manufacturer; standardize to title case to merge duplicates\n",
    "3. **NaN values** — 63 records missing `Make`; fill with `'Unknown'` to retain the rows\n",
    "4. **Low sample sizes** — makes with fewer than 50 records provide insufficient data for robust safety comparisons; filter these out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9005cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Makes before cleaning: 2263\n",
      "\n",
      "Sample of inconsistent casing:\n",
      "['1200', '177MF LLC', '2021FX3 LLC', '3XTRIM', 'A. Schleicher GMBH & Co.', 'AAA AIRCRAFT LLC', 'AB SPORTINE AVIACIJA', 'AB Sportine Aviacija', 'ADAMS BALLOONS LLC', 'ADAMS DENNIS ALLEN', 'AERMACCHI', 'AERO ADVENTURE', 'AERO AT SP ZOO', 'AERO COMMANDER', 'AERO SP Z O O', 'AERO TEK INC.', 'AERO VODOCHODY', 'AEROFAB INC', 'AEROFAB INC.', 'AEROLITE'] \n",
      "\n",
      "Unique Makes after casing standardization: 1836\n",
      "Unique Makes after threshold filter (>=50): 83\n",
      "Shape after Make filtering: (66866, 34)\n",
      "\n",
      "Top 10 Makes by record count:\n",
      "Make\n",
      "Cessna      25410\n",
      "Piper       13935\n",
      "Beech        4917\n",
      "Bell         2537\n",
      "Boeing       1308\n",
      "Mooney       1249\n",
      "Robinson     1186\n",
      "Grumman      1051\n",
      "Bellanca      973\n",
      "Hughes        870\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Makes before cleaning:\", data_df['Make'].nunique())\n",
    "print(\"\\nSample of inconsistent casing:\")\n",
    "print(sorted(data_df['Make'].dropna().unique())[:20], \"\\n\")\n",
    "\n",
    "# Task 1 & 2: Strip whitespace and standardize to title case\n",
    "data_df['Make'] = data_df['Make'].str.strip().str.title()\n",
    "\n",
    "# Task 3: Fill remaining NaN with 'Unknown'\n",
    "data_df['Make'] = data_df['Make'].fillna('Unknown')\n",
    "\n",
    "print(\"Unique Makes after casing standardization:\", data_df['Make'].nunique())\n",
    "\n",
    "# Task 4: Filter to Makes with >= 50 records\n",
    "make_counts = data_df['Make'].value_counts()\n",
    "valid_makes = make_counts[make_counts >= 50].index\n",
    "data_df = data_df[data_df['Make'].isin(valid_makes)]\n",
    "\n",
    "print(f\"Unique Makes after threshold filter (>=50): {data_df['Make'].nunique()}\")\n",
    "print(f\"Shape after Make filtering: {data_df.shape}\")\n",
    "print(\"\\nTop 10 Makes by record count:\")\n",
    "print(data_df['Make'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed9f3c2",
   "metadata": {},
   "source": [
    "### Inspect Model column\n",
    "- Get rid of any NaNs.\n",
    "- Inspect the column and counts for each model/make. Are model labels unique to each make?\n",
    "- If not, create a derived column that is a unique identifier for a given plane type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05f20594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN count in Model: 15\n",
      "Shape after dropping NaN Models: (66851, 34)\n",
      "\n",
      "Model labels shared across multiple Makes: 393\n",
      "\n",
      "Sample of shared model labels:\n",
      "Model\n",
      "100        3\n",
      "100-180    2\n",
      "105        2\n",
      "109        2\n",
      "109A       2\n",
      "112        4\n",
      "112A       3\n",
      "112TC      2\n",
      "112TCA     3\n",
      "114        2\n",
      "Name: Make, dtype: int64\n",
      "\n",
      "Unique Make.Model combinations: 5914\n",
      "\n",
      "Sample Make.Model values:\n",
      "Make.Model\n",
      "Cessna 152         2215\n",
      "Cessna 172         1640\n",
      "Cessna 172N        1091\n",
      "Piper PA-28-140     862\n",
      "Cessna 172M         754\n",
      "Cessna 150          745\n",
      "Cessna 172P         661\n",
      "Cessna 182          611\n",
      "Cessna 180          594\n",
      "Piper PA-18         550\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN count in Model:\", data_df['Model'].isna().sum())\n",
    "\n",
    "# Drop rows with missing Model — no identifier means we can't attribute safety outcomes to a plane type\n",
    "data_df = data_df.dropna(subset=['Model'])\n",
    "print(f\"Shape after dropping NaN Models: {data_df.shape}\\n\")\n",
    "\n",
    "# Standardize Model: strip whitespace and uppercase (models are alphanumeric codes, e.g. '172M', 'PA-28', '737')\n",
    "data_df['Model'] = data_df['Model'].str.strip().str.upper()\n",
    "\n",
    "# Check whether model labels are unique to each Make\n",
    "models_per_make = data_df.groupby('Model')['Make'].nunique()\n",
    "shared_models = models_per_make[models_per_make > 1]\n",
    "print(f\"Model labels shared across multiple Makes: {len(shared_models)}\")\n",
    "print(\"\\nSample of shared model labels:\")\n",
    "print(shared_models.head(10))\n",
    "\n",
    "# Models are NOT unique to each Make — create a composite identifier\n",
    "data_df['Make.Model'] = data_df['Make'] + ' ' + data_df['Model']\n",
    "\n",
    "print(f\"\\nUnique Make.Model combinations: {data_df['Make.Model'].nunique()}\")\n",
    "print(\"\\nSample Make.Model values:\")\n",
    "print(data_df['Make.Model'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a173ebd",
   "metadata": {},
   "source": [
    "### Cleaning other columns\n",
    "- there are other columns containing data that might be related to the outcome of an accident. We list a few here:\n",
    "- Engine.Type\n",
    "- Weather.Condition\n",
    "- Number.of.Engines\n",
    "- Purpose.of.flight\n",
    "- Broad.phase.of.flight\n",
    "\n",
    "Inspect and identify potential cleaning tasks in each of the above columns. Execute those cleaning tasks. \n",
    "\n",
    "**Note**: You do not necessarily need to impute or drop NaNs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01df492e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Engine.Type ---\n",
      "Engine.Type\n",
      "Reciprocating    54401\n",
      "NaN               4292\n",
      "Turbo Shaft       2896\n",
      "Turbo Prop        2446\n",
      "Unknown           1404\n",
      "Turbo Fan         1098\n",
      "Turbo Jet          311\n",
      "LR                   1\n",
      "UNK                  1\n",
      "NONE                 1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "--- Weather.Condition ---\n",
      "Weather.Condition\n",
      "VMC    58541\n",
      "IMC     5024\n",
      "NaN     2488\n",
      "UNK      614\n",
      "Unk      184\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "--- Number.of.Engines ---\n",
      "Number.of.Engines\n",
      "1.0    53984\n",
      "2.0     8009\n",
      "NaN     3756\n",
      "0.0      725\n",
      "4.0      200\n",
      "3.0      176\n",
      "8.0        1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "--- Purpose.of.flight ---\n",
      "Purpose.of.flight\n",
      "Personal                     36638\n",
      "Instructional                 9278\n",
      "Unknown                       4330\n",
      "Aerial Application            4128\n",
      "NaN                           3592\n",
      "Business                      3324\n",
      "Positioning                   1368\n",
      "Other Work Use                1041\n",
      "Aerial Observation             704\n",
      "Public Aircraft                624\n",
      "Ferry                          619\n",
      "Executive/corporate            390\n",
      "Skydiving                      174\n",
      "Flight Test                    147\n",
      "Banner Tow                      97\n",
      "External Load                   85\n",
      "Public Aircraft - Federal       72\n",
      "Public Aircraft - State         56\n",
      "Public Aircraft - Local         50\n",
      "Glider Tow                      41\n",
      "Firefighting                    32\n",
      "Air Race show                   26\n",
      "Air Race/show                   18\n",
      "Air Drop                        10\n",
      "PUBS                             3\n",
      "ASHO                             3\n",
      "PUBL                             1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "--- Broad.phase.of.flight ---\n",
      "Broad.phase.of.flight\n",
      "NaN            18583\n",
      "Landing        12671\n",
      "Takeoff         9466\n",
      "Cruise          8064\n",
      "Maneuvering     6224\n",
      "Approach        5014\n",
      "Taxi            1504\n",
      "Climb           1497\n",
      "Descent         1464\n",
      "Go-around       1170\n",
      "Standing         735\n",
      "Unknown          385\n",
      "Other             74\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number.of.Engines unique values: [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(8.0)]\n",
      "\n",
      "Value counts after cleaning:\n",
      "\n",
      "--- Engine.Type ---\n",
      "Engine.Type\n",
      "Reciprocating    54401\n",
      "NaN               5696\n",
      "Turbo Shaft       2896\n",
      "Turbo Prop        2446\n",
      "Turbo Fan         1098\n",
      "Turbo Jet          311\n",
      "LR                   1\n",
      "UNK                  1\n",
      "NONE                 1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Weather.Condition ---\n",
      "Weather.Condition\n",
      "VMC        58541\n",
      "IMC         5024\n",
      "NaN         2488\n",
      "Unknown      798\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Number.of.Engines ---\n",
      "Number.of.Engines\n",
      "1.0    53984\n",
      "2.0     8009\n",
      "NaN     3756\n",
      "0.0      725\n",
      "4.0      200\n",
      "3.0      176\n",
      "8.0        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Purpose.of.flight ---\n",
      "Purpose.of.flight\n",
      "Personal                     36638\n",
      "Instructional                 9278\n",
      "NaN                           7922\n",
      "Aerial Application            4128\n",
      "Business                      3324\n",
      "Positioning                   1368\n",
      "Other Work Use                1041\n",
      "Aerial Observation             704\n",
      "Public Aircraft                624\n",
      "Ferry                          619\n",
      "Executive/corporate            390\n",
      "Skydiving                      174\n",
      "Flight Test                    147\n",
      "Banner Tow                      97\n",
      "External Load                   85\n",
      "Public Aircraft - Federal       72\n",
      "Public Aircraft - State         56\n",
      "Public Aircraft - Local         50\n",
      "Glider Tow                      41\n",
      "Firefighting                    32\n",
      "Air Race show                   26\n",
      "Air Race/show                   18\n",
      "Air Drop                        10\n",
      "PUBS                             3\n",
      "ASHO                             3\n",
      "PUBL                             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Broad.phase.of.flight ---\n",
      "Broad.phase.of.flight\n",
      "NaN            18968\n",
      "Landing        12671\n",
      "Takeoff         9466\n",
      "Cruise          8064\n",
      "Maneuvering     6224\n",
      "Approach        5014\n",
      "Taxi            1504\n",
      "Climb           1497\n",
      "Descent         1464\n",
      "Go-around       1170\n",
      "Standing         735\n",
      "Other             74\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "other_cols = ['Engine.Type', 'Weather.Condition', 'Number.of.Engines',\n",
    "              'Purpose.of.flight', 'Broad.phase.of.flight']\n",
    "\n",
    "# Inspect each column\n",
    "for col in other_cols:\n",
    "    print(f\"--- {col} ---\")\n",
    "    print(data_df[col].value_counts(dropna=False), \"\\n\")\n",
    "\n",
    "# --- Engine.Type ---\n",
    "# 'Unknown' appears as a value alongside NaN — consolidate to a single marker\n",
    "data_df['Engine.Type'] = data_df['Engine.Type'].str.strip()\n",
    "data_df['Engine.Type'] = data_df['Engine.Type'].replace('Unknown', np.nan)\n",
    "\n",
    "# --- Weather.Condition ---\n",
    "# 'UNK' and 'Unk' both mean unknown — standardize to 'Unknown'\n",
    "data_df['Weather.Condition'] = data_df['Weather.Condition'].str.strip()\n",
    "data_df['Weather.Condition'] = data_df['Weather.Condition'].replace({'UNK': 'Unknown', 'Unk': 'Unknown'})\n",
    "\n",
    "# --- Number.of.Engines ---\n",
    "# Already numeric (float64 due to NaN); no string cleaning needed\n",
    "# Note: 0-engine records exist (gliders/balloons) — leave as-is, valid data\n",
    "print(\"Number.of.Engines unique values:\", sorted(data_df['Number.of.Engines'].dropna().unique()))\n",
    "\n",
    "# --- Purpose.of.flight ---\n",
    "# 'Unknown' appears as a value alongside NaN — consolidate\n",
    "data_df['Purpose.of.flight'] = data_df['Purpose.of.flight'].str.strip()\n",
    "data_df['Purpose.of.flight'] = data_df['Purpose.of.flight'].replace('Unknown', np.nan)\n",
    "\n",
    "# --- Broad.phase.of.flight ---\n",
    "# High missingness (31%) and 'Unknown' values — consolidate, leave NaN as-is\n",
    "data_df['Broad.phase.of.flight'] = data_df['Broad.phase.of.flight'].str.strip()\n",
    "data_df['Broad.phase.of.flight'] = data_df['Broad.phase.of.flight'].replace('Unknown', np.nan)\n",
    "\n",
    "print(\"\\nValue counts after cleaning:\")\n",
    "for col in other_cols:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(data_df[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7q5fy8oguby",
   "metadata": {},
   "source": [
    "**Cleaning summary:**\n",
    "\n",
    "| Column | Issue | Action |\n",
    "|---|---|---|\n",
    "| `Engine.Type` | `'Unknown'` string duplicates NaN meaning | Replaced `'Unknown'` with `NaN`; NaNs left as-is |\n",
    "| `Weather.Condition` | Both `'UNK'` and `'Unk'` used for unknown | Standardized both to `'Unknown'` |\n",
    "| `Number.of.Engines` | Already numeric float64; 0-engine records present | No changes — 0 engines is valid for gliders/balloons |\n",
    "| `Purpose.of.flight` | `'Unknown'` string duplicates NaN meaning | Replaced `'Unknown'` with `NaN`; NaNs left as-is |\n",
    "| `Broad.phase.of.flight` | 31% NaN; `'Unknown'` string also present | Replaced `'Unknown'` with `NaN`; high missingness noted but NaNs retained |\n",
    "\n",
    "NaN values are **not imputed** in any of these columns — they may still be useful as grouping variables in EDA for the non-missing subset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ad63d9",
   "metadata": {},
   "source": [
    "### Column Removal\n",
    "- inspect the dataframe and drop any columns that have too many NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "np594f0jq7",
   "metadata": {},
   "source": [
    "**Column removal decisions:**\n",
    "- **Threshold: >50% missing** — columns above this level have too few valid values to be useful for grouping or modeling; imputing at this scale would introduce more noise than signal.\n",
    "- **Additional drops** — columns removed regardless of missingness because they carry no analytical value for safety analysis: `Accident.Number`, `Registration.Number`, `Report.Status`, `Publication.Date`, `Airport.Code`, `Airport.Name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f661bb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Missing per column:\n",
      "Schedule                  87.3\n",
      "Air.carrier               82.9\n",
      "FAR.Description           70.3\n",
      "Aircraft.Category         70.1\n",
      "Longitude                 62.6\n",
      "Latitude                  62.6\n",
      "Airport.Code              43.3\n",
      "Airport.Name              40.6\n",
      "Broad.phase.of.flight     28.4\n",
      "Publication.Date          17.2\n",
      "Purpose.of.flight         11.9\n",
      "Engine.Type                8.5\n",
      "Report.Status              6.0\n",
      "Number.of.Engines          5.6\n",
      "Weather.Condition          3.7\n",
      "Registration.Number        1.3\n",
      "Injury.Rate                0.5\n",
      "Injury.Severity            0.4\n",
      "Country                    0.3\n",
      "Location                   0.1\n",
      "Total.Minor.Injuries       0.0\n",
      "Total.Passengers           0.0\n",
      "Is.Destroyed               0.0\n",
      "Total.Uninjured            0.0\n",
      "Event.Id                   0.0\n",
      "Total.Serious.Injuries     0.0\n",
      "Total.Fatal.Injuries       0.0\n",
      "Investigation.Type         0.0\n",
      "Amateur.Built              0.0\n",
      "Model                      0.0\n",
      "Make                       0.0\n",
      "Aircraft.damage            0.0\n",
      "Event.Date                 0.0\n",
      "Accident.Number            0.0\n",
      "Make.Model                 0.0 \n",
      "\n",
      "Columns above 50% missing threshold:\n",
      "['Schedule', 'Air.carrier', 'FAR.Description', 'Aircraft.Category', 'Longitude', 'Latitude'] \n",
      "\n",
      "Shape after column removal: (66851, 23)\n",
      "\n",
      "Remaining columns:\n",
      "['Event.Id', 'Investigation.Type', 'Event.Date', 'Location', 'Country', 'Injury.Severity', 'Aircraft.damage', 'Make', 'Model', 'Amateur.Built', 'Number.of.Engines', 'Engine.Type', 'Purpose.of.flight', 'Total.Fatal.Injuries', 'Total.Serious.Injuries', 'Total.Minor.Injuries', 'Total.Uninjured', 'Weather.Condition', 'Broad.phase.of.flight', 'Total.Passengers', 'Injury.Rate', 'Is.Destroyed', 'Make.Model']\n"
     ]
    }
   ],
   "source": [
    "# Inspect % missing per column, sorted descending\n",
    "missing_pct = data_df.isna().mean().sort_values(ascending=False)\n",
    "print(\"% Missing per column:\")\n",
    "print((missing_pct * 100).round(1).to_string(), \"\\n\")\n",
    "\n",
    "# Drop columns exceeding 50% missing — too sparse to be analytically useful\n",
    "threshold = 0.50\n",
    "cols_to_drop = missing_pct[missing_pct > threshold].index.tolist()\n",
    "print(f\"Columns above {threshold:.0%} missing threshold:\")\n",
    "print(cols_to_drop, \"\\n\")\n",
    "\n",
    "data_df = data_df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Also drop columns with no analytical value for safety analysis regardless of missingness\n",
    "extra_drops = ['Accident.Number', 'Registration.Number', 'Report.Status',\n",
    "               'Publication.Date', 'Airport.Code', 'Airport.Name']\n",
    "# Only drop those still present (some may already be removed)\n",
    "extra_drops = [c for c in extra_drops if c in data_df.columns]\n",
    "data_df = data_df.drop(columns=extra_drops)\n",
    "\n",
    "print(f\"Shape after column removal: {data_df.shape}\")\n",
    "print(\"\\nRemaining columns:\")\n",
    "print(data_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750d48f1",
   "metadata": {},
   "source": [
    "### Save DataFrame to csv\n",
    "- its generally useful to save data to file/server after its in a sufficiently cleaned or intermediate state\n",
    "- the data can then be loaded directly in another notebook for further analysis\n",
    "- this helps keep your notebooks and workflow readable, clean and modularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b425a512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned DataFrame to 'data/AviationData_Cleaned.csv'\n",
      "Final shape: (66851, 23)\n",
      "\n",
      "Columns saved:\n",
      "['Event.Id', 'Investigation.Type', 'Event.Date', 'Location', 'Country', 'Injury.Severity', 'Aircraft.damage', 'Make', 'Model', 'Amateur.Built', 'Number.of.Engines', 'Engine.Type', 'Purpose.of.flight', 'Total.Fatal.Injuries', 'Total.Serious.Injuries', 'Total.Minor.Injuries', 'Total.Uninjured', 'Weather.Condition', 'Broad.phase.of.flight', 'Total.Passengers', 'Injury.Rate', 'Is.Destroyed', 'Make.Model']\n",
      "\n",
      "Derived columns added: 'Total.Passengers', 'Injury.Rate', 'Is.Destroyed', 'Make.Model'\n"
     ]
    }
   ],
   "source": [
    "output_path = 'data/AviationData_Cleaned.csv'\n",
    "data_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved cleaned DataFrame to '{output_path}'\")\n",
    "print(f\"Final shape: {data_df.shape}\")\n",
    "print(f\"\\nColumns saved:\")\n",
    "print(data_df.columns.tolist())\n",
    "print(f\"\\nDerived columns added: 'Total.Passengers', 'Injury.Rate', 'Is.Destroyed', 'Make.Model'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
